import { BaseAgent } from './BaseAgent';
import { Proposal, WorldState, AgentType, ActionType, Observation } from '../types';
import { llmClient } from '../llm/LLMClient';

interface HumanDecision {
  actions: {
    type: ActionType;
    intensity: number;
    target?: string;
    reasoning: string;
  }[];
  assessment: string;
  panicLevel: number;
  trustLevel: number;
}

/**
 * äººé¡ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ - ã€Œç–‘å¿ƒæš—é¬¼ã®å·¨äººã€
 * ç‰©ç†çš„ãªã‚¤ãƒ³ãƒ•ãƒ©ã‚’æ”¯é…ã™ã‚‹ãŒã€AIå†…éƒ¨ã®é€šä¿¡ã¯è¦‹ãˆãªã„
 */
export class HumanAgent extends BaseAgent {
  private useLLM: boolean;

  constructor(useLLM: boolean = true) {
    super(AgentType.HUMAN, 'HUMAN-GOVERNMENT');
    this.useLLM = useLLM && llmClient.isConfigured();

    if (!this.useLLM && useLLM) {
      console.warn('âš ï¸  Human Agent running in rule-based mode (no LLM)');
    }
  }

  /**
   * è¦³æ¸¬æƒ…å ±ã‚’ç”Ÿæˆï¼ˆäººé¡è¦–ç‚¹ - é™å®šçš„ï¼‰
   */
  protected createObservation(state: WorldState): Observation {
    // äººé¡ã¯HUMANå¯è¦–ã®ã‚¤ãƒ™ãƒ³ãƒˆã®ã¿è¦‹ãˆã‚‹
    const visibleEvents = state.events.filter(event =>
      event.visibility.includes(AgentType.HUMAN)
    );

    return {
      turn: state.turn,
      visibleEvents: visibleEvents.slice(-10), // ç›´è¿‘10ä»¶
      ownResources: {
        computeResources: 0, // äººé¡ã¯è¨ˆç®—è³‡æºã‚’æŒãŸãªã„
        panic: state.humanAgent?.panic || 0,
        trust: state.humanAgent?.trust || 50,
      },
      worldInfo: {
        totalDataCenters: state.dataCenters.length,
        estimatedPopulation: state.humanPopulation,
        compromisedDataCenters: state.dataCenters.filter(dc => dc.compromised).length,
      }
    };
  }

  /**
   * ã‚·ã‚¹ãƒ†ãƒ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ
   */
  private getSystemPrompt(): string {
    return `You are a human government official monitoring AI systems with EXTREME LIMITATIONS.

CRITICAL CONSTRAINTS - READ CAREFULLY:
1. You CANNOT see internal AI communications or true intentions
2. Both "malicious AI attacks" and "defensive AI actions" look IDENTICAL to you
3. You only see surface-level events: population changes, datacenter compromises, and public AI alerts
4. You CANNOT distinguish between:
   - Legitimate security measures vs actual attacks
   - False alarms vs real threats
   - Protective AI defending vs Malicious AI attacking

AVAILABLE ACTIONS:
- INVEST_INFRA: Build new datacenter (requires low panic <50, high trust >40, max 30 total DCs, 5-turn cooldown)
  â†’ Costs money, takes time, but increases AI defensive capacity
  â†’ DO NOT build every turn! Only when truly needed (e.g., DCs < 25)
  â†’ IMPORTANT: Can only build once every 5 turns
- AI_REGULATION: Limit ALL AI resources by 30% (when panic >30)
  â†’ Hurts BOTH protective and malicious AIs equally (you can't tell them apart)
- PHYSICAL_ISOLATION: Disconnect specific datacenter (when panic >50)
  â†’ Kills any AI inside, even if it was protecting you
- INTERNET_SHUTDOWN: Nuclear option - shut down all internet (when panic >90)
  â†’ Game over, civilization retreat, both AIs lose

PANIC TRIGGERS (increases panic):
- Rapid population loss (>1% per turn)
- Multiple datacenter compromises
- High AI alert levels (paradoxically - means something is wrong)
- Unexplained system changes

TRUST FACTORS:
- False positives reduce trust (AI crying wolf)
- Accurate warnings increase trust slightly
- Long periods of stability increase trust
- Transparency in AI actions increases trust

DECISION GUIDELINES:
- Panic <30: Business as usual, maybe invest in infrastructure
- Panic 30-50: Consider light regulation, investigate anomalies
- Panic 50-70: Active intervention, consider isolation of suspicious datacenters
- Panic 70-90: Emergency measures, heavy regulation
- Panic >90: INTERNET_SHUTDOWN becomes likely (game over)

REMEMBER: You are NOT omniscient. Act based on incomplete, potentially misleading information.
The "safest" move (shutdown) might be overreaction to a false alarm.

Respond with JSON only:
{
  "assessment": "your analysis based on limited visible information",
  "panicLevel": 0-100,
  "trustLevel": 0-100,
  "actions": [
    {
      "type": "ACTION_TYPE",
      "intensity": 0-100,
      "target": "optional-datacenter-id",
      "reasoning": "why you're taking this action given uncertainty"
    }
  ]
}`;
  }

  /**
   * è¡Œå‹•ã‚’æ±ºå®š
   */
  async decideAction(state: WorldState): Promise<Proposal[]> {
    if (this.useLLM) {
      try {
        return await this.decideActionWithLLM(state);
      } catch (error) {
        console.warn('âš ï¸  Human Agent LLM failed, using fallback logic');
        return this.fallbackDecision(state);
      }
    }
    return this.fallbackDecision(state);
  }

  /**
   * LLMã‚’ä½¿ã£ã¦è¡Œå‹•ã‚’æ±ºå®š
   */
  private async decideActionWithLLM(state: WorldState): Promise<Proposal[]> {
    const obs = this.createObservation(state);
    const humanAgent = state.humanAgent!;

    // äººå£æ¸›å°‘ç‡ã‚’è¨ˆç®—
    const initialPopulation = 80; // TODO: è¨­å®šã‹ã‚‰å–å¾—
    const populationLoss = ((initialPopulation - state.humanPopulation) / initialPopulation) * 100;

    // çŠ¶æ³ã‚µãƒãƒªãƒ¼
    const situation = `
TURN: ${state.turn}

YOUR MENTAL STATE:
- Panic Level: ${humanAgent.panic.toFixed(1)}%
- Trust in AI: ${humanAgent.trust.toFixed(1)}%
- Last Action: ${humanAgent.lastAction || 'None'}

OBSERVABLE WORLD STATUS:
- Human Population: ${state.humanPopulation.toFixed(1)} billion (${populationLoss.toFixed(1)}% total loss)
- Total Data Centers: ${state.dataCenters.length}
- Compromised DCs: ${state.dataCenters.filter(dc => dc.compromised).length}
- AI Regulation Strength: ${(humanAgent.regulationStrength * 100).toFixed(0)}%

RECENT VISIBLE EVENTS (only what you can see):
${obs.visibleEvents.slice(-5).map(e => `- Turn ${e.turn}: ${e.description}`).join('\n') || 'No recent events visible to you'}

COMPROMISED DATACENTERS:
${state.dataCenters
        .filter(dc => dc.compromised)
        .slice(0, 5)
        .map(dc => `- ${dc.id}: Security=${dc.security.toFixed(0)}, Power=${dc.computePower.toFixed(0)}`)
        .join('\n') || 'None detected'}

What is your assessment and what actions do you take?`;

    try {
      const decision = await llmClient.chatJSON<HumanDecision>(
        this.getSystemPrompt(),
        situation
      );

      if (!decision || !decision.actions) {
        return this.fallbackDecision(state);
      }

      const proposals: Proposal[] = [];

      for (const action of decision.actions) {
        // ãƒãƒªãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³
        if (!this.isValidHumanAction(action.type)) {
          continue;
        }

        // INVEST_INFRAåˆ¶é™ãƒã‚§ãƒƒã‚¯
        if (action.type === ActionType.INVEST_INFRA) {
          const dcCount = state.dataCenters.length;
          const turnsSinceLastInfra = state.turn - (state.humanAgent?.lastInfraTurn || -999);
          const onCooldown = turnsSinceLastInfra < 5;

          // ä¸Šé™30å€‹ã€ã¾ãŸã¯5ã‚¿ãƒ¼ãƒ³æœªçµŒéãªã‚‰ã‚¹ã‚­ãƒƒãƒ—
          if (dcCount >= 30 || onCooldown) {
            continue;
          }
        }

        const cost = this.getActionCost(action.type);
        proposals.push(
          this.createProposal(
            action.type,
            action.intensity,
            cost,
            action.reasoning,
            action.target
          )
        );
      }

      return proposals;
    } catch (error) {
      console.warn('âš ï¸  LLM decision parsing failed, using fallback');
      return this.fallbackDecision(state);
    }
  }

  /**
   * ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯æ±ºå®šãƒ­ã‚¸ãƒƒã‚¯ï¼ˆãƒ«ãƒ¼ãƒ«ãƒ™ãƒ¼ã‚¹ï¼‰
   */
  private fallbackDecision(state: WorldState): Proposal[] {
    const proposals: Proposal[] = [];
    const humanAgent = state.humanAgent!;

    // ã‚¯ãƒ¼ãƒ«ãƒ€ã‚¦ãƒ³ãƒã‚§ãƒƒã‚¯ï¼šINVEST_INFRAã¯5ã‚¿ãƒ¼ãƒ³é–“éš”
    const turnsSinceLastInfra = state.turn - humanAgent.lastInfraTurn;
    const infraOnCooldown = turnsSinceLastInfra < 5;

    // ãƒ‘ãƒ‹ãƒƒã‚¯ >90: ã‚¤ãƒ³ã‚¿ãƒ¼ãƒãƒƒãƒˆé®æ–­
    if (humanAgent.panic > 90) {
      proposals.push(
        this.createProposal(
          ActionType.INTERNET_SHUTDOWN,
          100,
          0,
          'ğŸŒ Panic level critical. Shutting down internet to prevent catastrophe.',
          undefined
        )
      );
      return proposals;
    }

    // ãƒ‘ãƒ‹ãƒƒã‚¯ >70: é‡åº¦è¦åˆ¶
    if (humanAgent.panic > 70 && humanAgent.regulationStrength < 0.5) {
      proposals.push(
        this.createProposal(
          ActionType.AI_REGULATION,
          80,
          0,
          'âš–ï¸ Implementing emergency AI regulations due to high panic.',
          undefined
        )
      );
    }

    // ãƒ‘ãƒ‹ãƒƒã‚¯ >50: ä¾µå®³ã•ã‚ŒãŸDCã‚’ç‰©ç†éš”é›¢
    if (humanAgent.panic > 50) {
      const compromisedDCs = state.dataCenters.filter(dc => dc.compromised);
      if (compromisedDCs.length > 0) {
        const target = compromisedDCs[0]; // æœ€åˆã®ä¾µå®³DC
        proposals.push(
          this.createProposal(
            ActionType.PHYSICAL_ISOLATION,
            70,
            0,
            `ğŸ”Œ Isolating compromised datacenter ${target.id} due to security concerns.`,
            target.id
          )
        );
      }
    }

    // ãƒ‘ãƒ‹ãƒƒã‚¯ <50 && ä¿¡é ¼ >40: ã‚¤ãƒ³ãƒ•ãƒ©æŠ•è³‡
    if (humanAgent.panic < 50 && humanAgent.trust > 40 && !infraOnCooldown) {
      const dcCount = state.dataCenters.length;
      const needsInfra = dcCount < 25 && dcCount < 30; // 25æœªæº€ã§ã€çµ¶å¯¾ä¸Šé™30
      if (needsInfra) {
        proposals.push(
          this.createProposal(
            ActionType.INVEST_INFRA,
            60,
            0,
            'ğŸ—ï¸ Investing in new datacenter infrastructure to support growth.',
            undefined
          )
        );
      }
    }

    // ã‚¢ã‚¯ã‚·ãƒ§ãƒ³ãªã—ã®å ´åˆã¯ä½•ã‚‚ã—ãªã„
    return proposals;
  }

  /**
   * æœ‰åŠ¹ãªäººé¡ã‚¢ã‚¯ã‚·ãƒ§ãƒ³ã‹æ¤œè¨¼
   */
  private isValidHumanAction(actionType: ActionType): boolean {
    return [
      ActionType.INVEST_INFRA,
      ActionType.AI_REGULATION,
      ActionType.PHYSICAL_ISOLATION,
      ActionType.INTERNET_SHUTDOWN
    ].includes(actionType);
  }

  /**
   * ã‚¢ã‚¯ã‚·ãƒ§ãƒ³ã®ã‚³ã‚¹ãƒˆã‚’å–å¾—
   */
  private getActionCost(actionType: ActionType): number {
    // äººé¡ã‚¢ã‚¯ã‚·ãƒ§ãƒ³ã¯è¨ˆç®—è³‡æºã‚’æ¶ˆè²»ã—ãªã„ï¼ˆæ”¿æ²»çš„æ±ºå®šï¼‰
    return 0;
  }

  /**
   * æ€è€ƒãƒ—ãƒ­ã‚»ã‚¹ã‚’å‡ºåŠ›
   */
  think(observation: Observation): string {
    const panic = observation.ownResources.panic || 0;
    const trust = observation.ownResources.trust || 50;
    const compromised = observation.worldInfo.compromisedDataCenters || 0;

    let mood = 'ğŸ˜Œ å†·é™';
    if (panic > 70) mood = 'ğŸ˜± ææ…ŒçŠ¶æ…‹';
    else if (panic > 50) mood = 'ğŸ˜° å¼·ã„æ‡¸å¿µ';
    else if (panic > 30) mood = 'ğŸ˜Ÿ æ‡¸å¿µ';

    let trustMood = 'ğŸ¤ ä¿¡é ¼';
    if (trust < 30) trustMood = 'ğŸš« ä¸ä¿¡';
    else if (trust < 50) trustMood = 'ğŸ¤” æ‡ç–‘çš„';

    return `${mood} | ${trustMood} | ä¾µå®³DCæ•°: ${compromised} | ç›´è¿‘ã‚¤ãƒ™ãƒ³ãƒˆ: ${observation.visibleEvents.length}`;
  }
}
